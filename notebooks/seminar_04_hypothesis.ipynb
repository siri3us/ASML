{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\Sum}{\\sum\\limits}\n",
    "\\newcommand{\\Int}{\\int\\limits}\n",
    "\\newcommand{\\Intf}{\\int\\limits_{-\\infty}^{+\\infty}}\n",
    "\\newcommand{\\Prod}{\\prod\\limits}\n",
    "\\newcommand{\\Max}{\\max\\limits}\n",
    "\\newcommand{\\Min}{\\min\\limits}\n",
    "\\newcommand{\\Lim}{\\lim\\limits}\n",
    "\\newcommand{\\Prob}{\\mathsf{P}}\n",
    "\\newcommand{\\Var}{\\mathbb{V}}\n",
    "\\newcommand{\\Exp}{\\mathbb{E}}\n",
    "\\newcommand{\\argmax}{\\arg\\max}\n",
    "\\newcommand{\\Cov}{\\mathrm{Cov}}\n",
    "\\newcommand{\\makebold}[1]{\\boldsymbol{#1}}\n",
    "\\newcommand{\\mean}[1]{\\overline{#1}}\n",
    "\\newcommand{\\avg}[1]{\\left\\langle #1 \\right\\rangle}\n",
    "\\newcommand{\\lp}{\\left}\n",
    "\\newcommand{\\rp}{\\right}\n",
    "\\newcommand{\\eps}{\\varepsilon}\n",
    "\\newcommand{\\loss}{\\mathcal{L}}\n",
    "\\newcommand{\\Llr}{\\mathcal{L}}\n",
    "\\newcommand{\\llr}{\\ell}\n",
    "\\newcommand{\\RR}{\\mathbb{R}}\n",
    "\\newcommand{\\ZZ}{\\mathbb{Z}}\n",
    "\\newcommand{\\NN}{\\mathbb{N}}\n",
    "\\newcommand{\\boldtheta}{\\boldsymbol{\\theta}}\n",
    "\\newcommand{\\boldtau}{\\boldsymbol{\\tau}}\n",
    "\\newcommand{\\boldT}{\\boldsymbol{T}}\n",
    "\\newcommand{\\boldX}{\\boldsymbol{X}}\n",
    "\\newcommand{\\boldY}{\\boldsymbol{Y}}\n",
    "\\newcommand{\\boldZ}{\\boldsymbol{Z}}\n",
    "\\newcommand{\\boldtheta}{\\boldsymbol{\\theta}}\n",
    "\\newcommand{\\boldtau}{\\boldsymbol{\\tau}}\n",
    "\\newcommand{\\boldx}{\\boldsymbol{x}}\n",
    "\\newcommand{\\boldu}{\\boldsymbol{u}}\n",
    "\\newcommand{\\boldv}{\\boldsymbol{v}}\n",
    "\\newcommand{\\boldy}{\\boldsymbol{y}}\n",
    "\\newcommand{\\boldz}{\\boldsymbol{z}}\n",
    "\\newcommand{\\boldp}{\\boldsymbol{p}}\n",
    "\\newcommand{\\Poisson}{\\mathrm{Poisson}}\n",
    "\\newcommand{\\Uniform}{\\mathrm{Uniform}}\n",
    "\\newcommand{\\Binomial}{\\mathrm{Binomial}}\n",
    "\\newcommand{\\Bernoulli}{\\mathrm{Bernoulli}}\n",
    "\\newcommand{\\Gammap}{\\mathrm{Gamma}}\n",
    "\\newcommand{\\Normal}{\\mathcal{N}}\n",
    "\\newcommand{\\LogN}{\\mathrm{LogN}}\n",
    "\\newcommand{\\Exponential}{\\mathrm{Exp}}\n",
    "\\newcommand{\\Erlang}{\\mathrm{Erlang}}\n",
    "\\newcommand{\\Cauchy}{C}\n",
    "\\newcommand{\\lf}{\\left\\{}\n",
    "\\newcommand{\\rf}{\\right\\}}\n",
    "\\newcommand{\\lp}{\\left(}\n",
    "\\newcommand{\\rp}{\\right)}\n",
    "\\newcommand{\\ls}{\\left[}\n",
    "\\newcommand{\\rs}{\\right]}\n",
    "\\newcommand{\\lv}{\\left|}\n",
    "\\newcommand{\\rv}{\\right|}\n",
    "\\newcommand{\\Ecdf}[1]{\\hat{F}_n(#1)}\n",
    "\\newcommand{\\boot}{\\mathrm{boot}}\n",
    "\\newcommand{\\bias}{\\mathrm{bias}}\n",
    "\\newcommand{\\se}{\\mathrm{se}}\n",
    "\\newcommand{\\MSE}{\\mathrm{MSE}}\n",
    "\\newcommand{\\qm}{\\mathrm{qm}}\n",
    "\\newcommand{\\as}{\\mathrm{as}}\n",
    "\\newcommand{\\trace}{\\mathrm{trace}}\n",
    "\\newcommand{\\hatp}{\\hat{p}}\n",
    "\\newcommand{\\esttheta}{\\hat{\\theta}}\n",
    "\\newcommand{\\estlambda}{\\hat{\\lambda}}\n",
    "\\newcommand{\\estmu}{\\hat{\\mu}}\n",
    "\\newcommand{\\estsigma}{\\hat{\\sigma}}\n",
    "\\newcommand{\\estalpha}{\\hat{\\alpha}}\n",
    "\\newcommand{\\estbeta}{\\hat{\\beta}}\n",
    "\\newcommand{\\estxi}{\\hat{\\xi}}\n",
    "\\newcommand{\\esttau}{\\hat{\\tau}}\n",
    "\\newcommand{\\estpsi}{\\hat{\\psi}}\n",
    "\\newcommand{\\esta}{\\hat{a}}\n",
    "\\newcommand{\\estb}{\\hat{b}}\n",
    "\\newcommand{\\estc}{\\hat{c}}\n",
    "\\newcommand{\\estd}{\\hat{d}}\n",
    "\\newcommand{\\estp}{\\hat{p}}\n",
    "\\newcommand{\\estT}{\\hat{T}}\n",
    "\\newcommand{\\estR}{\\hat{R}}\n",
    "\\newcommand{\\estF}{\\hat{F}}\n",
    "\\newcommand{\\estf}{\\hat{f}}\n",
    "\\newcommand{\\estC}{\\hat{C}}\n",
    "\\newcommand{\\estS}{\\hat{S}}\n",
    "\\newcommand{\\estY}{\\hat{Y}}\n",
    "\\newcommand{\\esty}{\\hat{y}}\n",
    "\\newcommand{\\estVar}{\\hat{\\Var}}\n",
    "\\newcommand{\\estExp}{\\hat{\\Exp}}\n",
    "\\newcommand{\\estSe}{\\hat{\\se}}\n",
    "\\newcommand{\\tiltau}{\\tilde{\\tau}}\n",
    "\\newcommand{\\tiltheta}{\\tilde{\\theta}}\n",
    "\\newcommand{\\tillambda}{\\tilde{\\lambda}}\n",
    "\\newcommand{\\tilsigma}{\\tilde{\\sigma}}\n",
    "\\newcommand{\\mlexi}{\\xi_{MLE}}\n",
    "\\newcommand{\\mletheta}{\\theta_{MLE}}\n",
    "\\newcommand{\\mlelambda}{\\lambda_{MLE}}\n",
    "\\newcommand{\\mlesigma}{\\sigma_{MLE}}\n",
    "\\newcommand{\\mmxi}{\\xi_{MM}}\n",
    "\\newcommand{\\mmtheta}{\\theta_{MM}}\n",
    "\\newcommand{\\mmlambda}{\\lambda_{MM}}\n",
    "\\newcommand{\\mmsigma}{\\sigma_{MM}}\n",
    "\\newcommand{\\mmgamma}{\\gamma_{MM}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестирование гипотез"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from itertools import product\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.collections import PolyCollection\n",
    "from matplotlib.colors import colorConverter\n",
    "%matplotlib inline\n",
    "\n",
    "titlesize = 24\n",
    "labelsize = 22\n",
    "legendsize = 22\n",
    "xticksize = 18\n",
    "yticksize = xticksize\n",
    "\n",
    "matplotlib.rcParams['legend.markerscale'] = 1.5     # the relative size of legend markers vs. original\n",
    "matplotlib.rcParams['legend.handletextpad'] = 0.5\n",
    "matplotlib.rcParams['legend.labelspacing'] = 0.4    # the vertical space between the legend entries in fraction of fontsize\n",
    "matplotlib.rcParams['legend.borderpad'] = 0.5       # border whitespace in fontsize units\n",
    "matplotlib.rcParams['font.size'] = 12\n",
    "matplotlib.rcParams['font.family'] = 'serif'\n",
    "matplotlib.rcParams['font.serif'] = 'Times New Roman'\n",
    "matplotlib.rcParams['axes.labelsize'] = labelsize\n",
    "matplotlib.rcParams['axes.titlesize'] = titlesize\n",
    "\n",
    "matplotlib.rc('xtick', labelsize=xticksize)\n",
    "matplotlib.rc('ytick', labelsize=yticksize)\n",
    "matplotlib.rc('legend', fontsize=legendsize)\n",
    "\n",
    "USETEX = False\n",
    "if USETEX:\n",
    "    matplotlib.rc('font', **{'family':'serif'})\n",
    "    matplotlib.rc('text', usetex=True)\n",
    "    matplotlib.rc('text.latex', unicode=True)\n",
    "    matplotlib.rc('text.latex', preamble=r'\\usepackage[utf8]{inputenc}')\n",
    "    matplotlib.rc('text.latex', preamble=r'\\usepackage[english]{babel}')\n",
    "    matplotlib.rc('text.latex', preamble=r'\\usepackage{amsmath}')\n",
    "\n",
    "SAVE_FIG = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='_toc'></a>\n",
    "# Содержание\n",
    "* [Теория](#theory)\n",
    "* [Примеры](#examples)\n",
    "    * [Одномерное нормальное распределения](#hypo_normal)\n",
    "    * [Тестирование гипотезы $H_0\\colon p = p_0$ для $\\boldX \\sim \\Bernoulli(p)$](#hypo_binomial)\n",
    "* [Критерий Вальда](#test_wald)\n",
    "* [Критерий отношения правдоподобий](#test_llr)\n",
    "* [Критерий Неймана-Пирсона](#test_np)\n",
    "* [Критерий хи-квадрат](#test_chi2)\n",
    "* [Критерий Колмогорова](#test_kolmogorov)\n",
    "* [Критерий перестановок](#test_permutation)\n",
    "* [Задачи](#tasks)\n",
    "    * [Задача 1. Подбрасывание монетки](#hypo_binomial_task1)\n",
    "    * [Задача 2. Сравнение алгоритмов предсказания](#comparing_prediction_algorithms)\n",
    "    * [Задача 3.](#test_chi2_task1)\n",
    "    * [Задача 4.](#test_chi2_task2)\n",
    "    * [Задача 5.](#test_chi2_task3)\n",
    "    * [Задача 6.](#test_permutation_task1)\n",
    "    * [Задача 7.](#test_np_task1)\n",
    "    * [Задача 8.](#test_np_task2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='theory'></a>\n",
    "# Теория<sup>[toc](#_toc)</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Статистической гипотезой** (или просто гипотезой) называется любое утверждение о виде или свойствах распределения наблюдаемых в эксперименте случайных величин. Статистическая гипотеза называется **простой**, если однозначно фиксирует распределение наблюдений. Иначе это **сложная** гипотеза. Проверяемая гипотеза называется нулевой $(H_0)$. Любая гипотеза о распределении наблюдаемой случайной величины, которая может оказаться истинной, но отличается от основной гипотезы, называется **альтернативной** гипотезой. Правило, согласно которому проверяют гипотезу $H_0$ (принимают или отвергают), называется **статистическим критерием** проверки\n",
    "гипотезы $H_0$. Статистическая гипотеза называется **параметрической**, если она представляет из себя предположение о том, что неизвестный параметр распределения (дисперсия, математическое ожидание и т.п.) имеет наперед заданное значение или множество значений. В процессе проверки $H_0$ можно принять правильное решение или совершить ошибку.\n",
    "\n",
    "* Вероятностью **ошибки первого рода** называется вероятность отклонить $H_0$, когда $H_0$ верна.\n",
    "* Вероятностью **ошибки второго рода** называется вероятность принять $H_0$, когда $H_0$ не верна.\n",
    "\n",
    "Вероятность $\\Prob_{H_1}(H_1)$ называется **мощностью критерия**. Понятие мощности определено только для случая простых $H_0$ и $H_1$. Существенно, что множество $\\Theta_1$ состоит из единственной точки $\\theta_1$.\n",
    "\n",
    "В случае сложных гипотез $H_0$ и $H_1$ говорят о **равномерно наиболее мощном критерии (р.н.м.к.) размера $\\alpha$**. Это такой статистический критерий с заданным размером (уровнем значимости) $\\alpha$ для\n",
    "проверки сложной гипотезы $H_0$ против сложной альтернативы $H_1$, мощность которого не меньше мощности любого другого статистического критерия, предназначенного для проверки $H_0$ против $H_1$ и имеющего тот же размер $\\alpha$.\n",
    " \n",
    "Критерий для проверки гипотезы $H_0$ против простой альтернативы $H_1$ называется **состоятельным**, если\n",
    "$$\n",
    "\\Prob_{H_1}(H_1) \\rightarrow 1, \\text{ если } n \\rightarrow \\infty.\n",
    "$$\n",
    "\n",
    "Критерий размера $\\alpha$, имеющий мощность не меньше $\\alpha$, называется **несмещенным**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='examples'></a>\n",
    "# Примеры<sup>[toc](#_toc)</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='hypo_normal'></a>\n",
    "## Одномерное нормального распределение<sup>[toc](#_toc)</sup>\n",
    "Дана выборка $\\boldX \\sim \\Normal(\\mu,\\sigma^2)$. Требуется написать критерий вида $T(\\boldX) > c$ для различения гипотез\n",
    "$$\n",
    "H_0\\colon \\mu < \\mu_0 \\text{ против } H_1\\colon \\mu \\ge \\mu_0.\n",
    "$$\n",
    "\n",
    "Возьмем в качестве статистики выборочное среднее\n",
    "$$\n",
    "T(\\boldX) = \\mean{\\boldX} = \\frac{1}{n}\\Sum_{i = 1}^n X_i.\n",
    "$$\n",
    "Мощность теста равна\n",
    "$$\n",
    "\\beta(\\mu, c) = \\Prob_{\\mu}(T(\\boldX) > c) = \\Int_{c}^{+\\infty} \\frac{\\sqrt{n}}{\\sqrt{2\\pi}\\sigma} e^{-\\frac{n(x - \\mu)^2}{2\\sigma^2}} dx = \\int_{\\frac{\\sqrt{n}(c-\\mu)}{\\sigma}}^{+\\infty} \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{x^2}{2}} dx = 1 - \\Phi\\lp\\frac{\\sqrt{n}(c - \\mu)}{\\sigma}\\rp.\n",
    "$$\n",
    "\n",
    "Хотим получить критерий размера $\\alpha$, т.е.\n",
    "$$\n",
    "\\alpha = \\sup_{\\mu \\in \\Theta_0} \\Prob_{\\mu}(T(\\boldX) > c) = 1 - \\Phi\\lp\\frac{\\sqrt{n}(c - \\mu_0)}{\\sigma}\\rp.\n",
    "$$\n",
    "Пусть размер выборки фиксирован. Тогда подбираем порог $c$:\n",
    "$$\n",
    "c = \\frac{\\sigma\\Phi^{-1}(1 - \\alpha)}{\\sqrt{n}} + \\mu_0.\n",
    "$$\n",
    "Также можно понять, какой размер выборки необходим при фиксированных $\\alpha$ и $c$.\n",
    "$$\n",
    "n \\ge \\lp\\frac{\\sigma\\Phi^{-1}(1 - \\alpha)}{c - \\mu_0}\\rp^2.\n",
    "$$\n",
    "Хотя подбор размера выборки более характерен в ситуациях, когда есть требования к мощности критерия, т.е. вероятности ошибок второго рода.\n",
    "\n",
    "Далее будем считать, что $\\mu_0 = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проверим на искуственных данных, что при $c = c(\\alpha)$ вероятность ошибки первого рода не превосходит $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 1\n",
    "mu = 0\n",
    "alpha = 0.05\n",
    "n_samples = 100\n",
    "\n",
    "gen = scipy.stats.norm(loc=mu, scale=sigma)\n",
    "c_alpha = scipy.stats.norm.ppf(1 - alpha, loc=0.0, scale=sigma / np.sqrt(n_samples))\n",
    "\n",
    "statistics = []\n",
    "n_runs = 40000\n",
    "for n_run in range(n_runs):\n",
    "    samples = gen.rvs(size=n_samples, random_state=n_run)\n",
    "    statistics.append(np.mean(samples))\n",
    "print('Requested test size = {}'.format(alpha))\n",
    "print('Estimated test size = {}'.format(np.mean(statistics > c_alpha)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='hypo_norm1_plot_power'></a>\n",
    "### Построение функции мощности<sup>[toc](#_toc)</sup>\n",
    "В качестве $c$ возьмем $c(\\alpha)$, т.е. строим функцию мощности $\\beta(\\mu,c(\\alpha))$ для критерия размера $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1     # Запрошенный нами размер теста\n",
    "sigma = 1       # N(mu, 1)\n",
    "n_samples = 10  # Размер выборки\n",
    "\n",
    "# Формирование диапазона средних значений, участвующих в рассмотрении\n",
    "mu_left = -5\n",
    "mu_right = 5\n",
    "n_points = 501\n",
    "mu_values = np.linspace(mu_left, mu_right, n_points)\n",
    "\n",
    "gen = scipy.stats.norm(loc=0.0, scale=sigma)  # Генератор N(0, sigma)\n",
    "c_alpha = sigma * gen.ppf(1 - alpha) / np.sqrt(n_samples)\n",
    "print('Critical value c(alpha) =', c_alpha)\n",
    "power = 1 - gen.cdf(np.sqrt(n_samples) * (c_alpha - mu_values) / sigma)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "# Отрисовка функции мощности теста\n",
    "plt.plot(mu_values, power, color='b', zorder=3)\n",
    "# Отрисовка прямой y=alpha\n",
    "plt.plot([mu_left, mu_right], [alpha, alpha], color='k', linestyle='--', label=r'$\\alpha$', zorder=3)\n",
    "\n",
    "plt.xlabel(r'$\\mu$')\n",
    "plt.ylabel(r'$\\beta(\\mu,c(\\alpha))$')\n",
    "plt.title(r'$\\beta(\\mu, c(\\alpha))$');\n",
    "plt.grid(which='both', alpha=0.5, linestyle='--');\n",
    "plt.legend(fontsize=24);\n",
    "\n",
    "if SAVE_FIG:\n",
    "    plt.savefig(os.path.join(pictures_dir, 'hypo_normal_power.pdf'), format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При каждом $\\mu$ тестовая статистика $T(\\boldX) = \\mean{\\boldX}$ обладает нормальным распределением $\\Normal(\\mu,\\sigma^2/n)$. Отрисуем эти распределения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "sigma = 1\n",
    "n_samples = 20\n",
    "gen = scipy.stats.norm(scale=sigma)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "# Plotting OX and OY axis\n",
    "plt.plot([-0.75, 1.25], [0, 0], color='k', linewidth=2)\n",
    "plt.plot([0, 0], [-1.5, 2.0], color='k', linewidth=2)\n",
    "\n",
    "# Power function for T(X) = mean(X)\n",
    "mu_values = np.linspace(-0.5, 1.25, 151)\n",
    "c_alpha = scipy.stats.norm.ppf(1 - alpha, loc=0.0, scale=sigma / np.sqrt(n_samples))\n",
    "power_function = 1.0 - scipy.stats.norm.cdf(np.sqrt(n_samples) * (c_alpha - mu_values) / sigma)\n",
    "plt.plot(mu_values, power_function, color='r', zorder=4,\n",
    "         label=r'$\\beta(\\mu, c(\\alpha))$ for $T(X) = \\overline{X}$')\n",
    "\n",
    "# Choosing mu values for which distributions of mean(X) is to be plotted\n",
    "mu_values = [-0.5, -0.25, 0, 0.5, 0.75, 1.0, 1.25]\n",
    "c_alpha = scipy.stats.norm.ppf(1 - alpha, loc=0.0, scale=sigma / np.sqrt(n_samples))\n",
    "mu_values.append(c_alpha)\n",
    "plt.plot([-0.75, max(mu_values)], [c_alpha, c_alpha], color='b', zorder=2, label=r'$c(\\alpha)$')\n",
    "plt.plot([c_alpha, c_alpha], [-1.5, 2], color='b', zorder=2)\n",
    "\n",
    "# Plotting PDFs for all mu's\n",
    "for mu in mu_values:\n",
    "    stddev = sigma / np.sqrt(n_samples)\n",
    "    gen = scipy.stats.norm(loc=mu, scale=stddev)\n",
    "    x = np.linspace(mu - 3 * stddev, mu + 3 * stddev, 101)\n",
    "    x_upp = x[x >= c_alpha]\n",
    "    x_low = x[x < c_alpha]\n",
    "    if len(x_upp) > 0:\n",
    "        y_upp = gen.pdf(x_upp)\n",
    "        plt.fill_betweenx(y=x_upp, x1=mu - 0.1 * y_upp, x2=mu, color='r', alpha=0.3, zorder=2)\n",
    "    if len(x_low) > 0:\n",
    "        y_low = gen.pdf(x_low)\n",
    "        plt.fill_betweenx(y=x_low, x1=mu - 0.1 * y_low, x2=mu, color='b', alpha=0.2, zorder=2)\n",
    "\n",
    "plt.ylim([-1., 2.])\n",
    "plt.plot(mu_values, mu_values, color='k', label=r'line of $\\mu$ values', marker='*', linestyle='--')\n",
    "plt.grid(which='both', alpha=1, linestyle=':')\n",
    "plt.xlabel(r'$\\mu$')\n",
    "plt.ylabel(r'$\\beta(\\mu)$')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение функций мощности для различных размеров выборок<sup>[toc](#_toc)</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 1\n",
    "n_samples_values = [5, 10, 25, 50, 75, 100]\n",
    "gen = scipy.stats.norm(scale=sigma)\n",
    "\n",
    "mu_left = -0.5\n",
    "mu_right = 1.5\n",
    "n_points = 201\n",
    "mu_values = np.linspace(mu_left, mu_right, n_points)\n",
    "\n",
    "# Цвета различных функций мощности\n",
    "cmap = plt.get_cmap('jet')\n",
    "colors = np.linspace(0.1, 0.9, len(n_samples_values))\n",
    "\n",
    "colors = list(map(cmap, colors))\n",
    "plt.figure(figsize=(10, 8))\n",
    "for n_plot, n_samples in enumerate(n_samples_values):\n",
    "    color = colors[n_plot]\n",
    "    c_alpha = sigma * gen.ppf(1 - alpha) / np.sqrt(n_samples)\n",
    "    power = 1 - gen.cdf(np.sqrt(n_samples) * (c_alpha - mu_values) / sigma)\n",
    "    plt.plot(mu_values, power, color=color, label=r'$n = {}$'.format(n_samples), zorder=3)\n",
    "\n",
    "# Отрисовка осей OX, OY\n",
    "plt.plot([mu_left, mu_right], [0, 0], color='k', linestyle='-', zorder=3)\n",
    "plt.plot([0, 0], [0.0, 1.0], color='k', linestyle='-', zorder=3)\n",
    "\n",
    "plt.xlabel(r'$\\mu$');\n",
    "plt.ylabel(r'$\\beta(\\mu,c(\\alpha))$');\n",
    "plt.grid(which='both', alpha=0.5, linestyle='--');\n",
    "plt.legend(fontsize=20);\n",
    "if SAVE_FIG:\n",
    "    plt.savefig(os.path.join(pictures_dir, 'hypo_normal_power_n.pdf'), format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power function for $T(\\boldX) = \\text{median}(\\boldX)$<sup>[toc](#_toc)</sup>\n",
    "$$\n",
    "\\mean{\\boldX} \\sim \\Normal\\left(\\mu,\\frac{\\sigma^2}{n}\\right), \\quad \\text{median}(\\boldX) \\sim \\Normal\\left(\\mu, \\frac{\\pi}{2}\\frac{\\sigma^2}{n}\\right). \n",
    "$$\n",
    "Функция мощности для медианы в области $\\mu > 0$ всюду меньше, чем функция мощности для выборочного среднего. Таким образом, тест на основе выборочного среднего мощнее теста на основе медианы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 1\n",
    "alpha = 0.1\n",
    "n_samples = 5\n",
    "mu_values = np.linspace(-2, 2, 201)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Power function for T(X) = mean(X)\n",
    "c_alpha = scipy.stats.norm.ppf(1 - alpha, loc=0.0, scale=sigma / np.sqrt(n_samples))\n",
    "power_function = 1.0 - scipy.stats.norm.cdf(np.sqrt(n_samples) * (c_alpha - mu_values) / sigma)\n",
    "plt.plot(mu_values, power_function, color='b', zorder=4, label=r'$\\beta(\\mu)$ for $T(X) = \\overline{X}$')\n",
    "\n",
    "# Power function for T(X) = median(X)\n",
    "c_alpha = scipy.stats.norm.ppf(1 - alpha, loc=0.0, scale=np.sqrt(np.pi/2) * sigma / np.sqrt(n_samples))\n",
    "power_function = 1.0 - scipy.stats.norm.cdf(np.sqrt(n_samples) * (c_alpha - mu_values) / (np.sqrt(np.pi/2) * sigma))\n",
    "plt.plot(mu_values, power_function, color='m', zorder=4, label=r'$\\beta(\\mu)$ for $T(X) = \\text{median}{X}$')\n",
    "\n",
    "\n",
    "plt.legend();\n",
    "plt.grid(which='both', alpha=1, linestyle=':');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='hypo_norm_mean_vs_median'></a>\n",
    "## [Not ready] $T(\\boldX) = \\mean{\\boldX}$ vs $T(\\boldX) = \\text{median}(\\boldX)$<sup>[toc](#_toc)</sup>\n",
    "Пусть $\\boldX \\sim F$.\n",
    "\n",
    "Если $E[X] = \\mu$, $V[X] = \\sigma^2$, то\n",
    "$$\n",
    "\\overline{\\boldX} \\xrightarrow[n\\to\\infty]{D} \\Normal\\left(\\mu, \\frac{\\sigma^2}{n}\\right), \\qquad\n",
    "\\text{median}(\\boldX) \\xrightarrow[n\\to\\infty]{D} \\Normal\\left(\\mu, \\frac{\\pi}{2}\\frac{\\sigma^2}{n}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "P_{H_0}(\\overline{\\boldX} > c) = \\alpha \\Rightarrow  c(\\alpha)\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "P_{H_0}(\\text{median}(\\boldX) > c) = \\alpha \\Rightarrow c(\\alpha)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 1\n",
    "n_samples = 5\n",
    "alpha = 0.05\n",
    "# Critical value for T(X) = median(X)\n",
    "c_alpha_median = scipy.stats.norm.ppf(1 - alpha, loc=0.0, scale=np.sqrt(np.pi/2) * sigma / np.sqrt(n_samples))\n",
    "# Critical value for T(X) = mean(X)\n",
    "c_alpha_mean  = scipy.stats.norm.ppf(1 - alpha, loc=0.0, scale=sigma / np.sqrt(n_samples))\n",
    "print('c(alpha) for T=median:', c_alpha_median)\n",
    "print('c(alpha) for T=mean:  ', c_alpha_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 100000\n",
    "gen = scipy.stats.norm(loc=0, scale=sigma)\n",
    "results_mean = []\n",
    "results_median = []\n",
    "for n_run in tqdm(range(n_runs)):\n",
    "    samples = gen.rvs(size=n_samples, random_state=n_run)\n",
    "    mean = np.mean(samples)\n",
    "    median = np.median(samples)\n",
    "    results_mean.append(int(mean > c_alpha_mean))\n",
    "    results_median.append(int(median > c_alpha_median))\n",
    "print('Type I error for mean:  ', np.mean(results_mean))\n",
    "print('Type I error for median:', np.mean(results_median))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_ratio = np.mean(np.equal(results_mean, results_median))\n",
    "print('Equal predictions rate:', equal_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_mean = np.mean(results_mean)\n",
    "p_mean_std = np.sqrt(p_mean * (1 - p_mean) / len(results_mean))\n",
    "print('p_mean   = {}, p_mean_std   = {}'.format(p_mean, p_mean_std))\n",
    "\n",
    "p_median = np.mean(results_median)\n",
    "p_median_std = np.sqrt(p_median * (1 - p_median) / len(results_median))\n",
    "print('p_median = {}, p_median_std = {}'.format(p_median, p_median_std))\n",
    "\n",
    "W = (p_mean - p_median) / np.sqrt(p_mean_std**2 + p_median_std**2)\n",
    "pvalue = 2 * (1 - scipy.stats.norm.cdf(abs(W), loc=0.0, scale=1.0))\n",
    "print('W = {}, pvalue = {}'.format(W, pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='hypo_binomial'></a>\n",
    "## Тестирование гипотезы $H_0\\colon p = p_0$ для $\\boldX \\sim \\Bernoulli(p)$<sup>[toc](#_toc)</sup>\n",
    "* [Честный подсчет функции мощности](#true_power_function)\n",
    "* [Построение критерия с помощью неравенства Чебышева](#power_function_cheb_inequality)\n",
    "* [Построение критерия с помощью неравенства Хёффдинга](#power_function_hoff_inequality)\n",
    "* [Аппроксимация функции мощности с помощью ЦПТ](#power_function_clt_approx)\n",
    "* [Различные варианты оценки функции мощности $\\beta(p, c)$](#power_function_various_estimates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть дана выборка $\\boldX =\\{X_1,\\dots,X_n\\} \\sim \\Bernoulli(p)$. По $\\boldX$ требуется построить критерий для различения гипотез\n",
    "$$\n",
    "H_0 \\colon p = p_0 \\text{ против } H_1\\colon p\\neq p_0.\n",
    "$$\n",
    "Будем строить критерий вида: **если $|\\mean{\\boldX} - p_0| > c$, то отклоняем $H_0$**. Т.е. в качестве тестовой статистики рассматривается $T(\\boldX) = |\\mean{\\boldX} - p_0|$. Для построения критерия уровня значимости $\\alpha$ требуется подобрать такой порог $c$, чтобы было выполнено условие:\n",
    "$$\n",
    "P_{p = p_0}(|\\mean{\\boldX} - p_0| > c) \\le \\alpha.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='true_power_function'></a>\n",
    "### Честный подсчет функции мощности<sup>[toc](#_toc)</sup>\n",
    "$$\n",
    "P_{p}(|\\mean{\\boldX} - p_0| \\le c) = P_{p}(n(p_0 - c) \\le \\Sum X_i \\le n(p_0 + c)) = \\Sum_{k = \\max\\{\\lceil n(p_0-c)\\rceil, 0\\}}^{\\min\\{\\lfloor n(p_0+c)\\rfloor, n\\}} C^k_n p^k (1 - p)^{n-k}.\n",
    "$$\n",
    "\n",
    "Поэтому для мощности критерия получаем\n",
    "$$\n",
    "\\beta(p,c) = P_{p}(|\\mean{\\boldX} - p_0| > c) = 1 - P_{p}(|\\mean{\\boldX} - p_0| \\le c) = 1 - \\Sum_{k = \\max\\{\\lceil n(p_0-c)\\rceil, 0\\}}^{\\min\\{\\lfloor n(p_0+c)\\rfloor, n\\}} C^k_n p^k (1 - p)^{n-k}.\n",
    "$$\n",
    "Это \"истинная\" функция мощности рассматриваемого критерия. Вероятность ошибки первого рода равна\n",
    "$$\n",
    "P_I(c) = \\beta(p_0,c) = 1 - \\Sum_{k = \\max\\{\\lceil n(p_0-c)\\rceil, 0\\}}^{\\min\\{\\lfloor n(p_0+c)\\rfloor, n\\}} C^k_n p_0^k (1 - p_0)^{n-k}.\n",
    "$$\n",
    "Вероятность ошибки первого рода есть функция от порога $c$, поэтому данный порог подбирается таким образом, чтобы было выполнено условие на уровень значимости теста\n",
    "$$\n",
    "P_I(c) = 1 - \\Sum_{k = \\max\\{\\lceil n(p_0-c)\\rceil, 0\\}}^{\\min\\{\\lfloor n(p_0+c)\\rfloor, n\\}} C^k_n p_0^k (1 - p_0)^{n-k} \\le \\alpha.\n",
    "$$\n",
    "Заметим, что функция $P_I(c)$ является ступенчатой. Поэтому, запрашивая критерий уровня значимости $\\alpha$ мы скорее всего получим тест размера $\\alpha^*$, меньшего чем $\\alpha$ (размер теста меньше или равен уровню значимости). Т.е. в данном примере проявляется идейная разница между понятиями уровня значимости теста, и размера теста."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее мы рассмотрим способы построения критерия, опирающиеся на различные вероятностные неравенства и предельные распределения. В каждом конкретном способе при построении критерия запрошенного уровня значимости $\\alpha$ находится некоторый порог $c(\\alpha)$. Однако нам также интересен и размер получившегося теста $\\alpha^*(c)$, который в общем случае меньше запрошенного уровня значимости $\\alpha$.  Т.е. получаем следующую цепочку действий:\n",
    "$$\n",
    "\\alpha \\Rightarrow c(\\alpha) \\Rightarrow \\alpha^*(c) = P_I(c).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='power_function_cheb_inequality'></a>\n",
    "### Построение критерия с помощью неравенства Чебышева<sup>[toc](#_toc)</sup>\n",
    "\n",
    "**Неравенство Чебышева:**\n",
    "$$\n",
    "P(|\\xi - \\Exp [\\xi]| > \\eps) \\le \\frac{\\Var [\\xi]}{\\eps^2}.\n",
    "$$\n",
    "\n",
    "Применительно к рассматраиваемой ситуации\n",
    "$$\n",
    "\\beta(p, c) = P_{p }(|\\mean{\\boldX} - p| > c) \\le \\frac{\\Var_{p}[\\mean{\\boldX}]}{c^2} =  \\frac{p(1-p)}{nc^2}.\n",
    "$$\n",
    "$$\n",
    "P_{I}(c) = \\beta(p_0, c) \\le \\frac{p_0(1-p_0)}{nc^2} = \\alpha.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='power_function_hoff_inequality'></a>\n",
    "### Построение критерия с помощью неравенства Хёффдинга<sup>[toc](#_toc)</sup>\n",
    "\n",
    "**Неравенство Хёффдинга.** Пусть $X_1,\\dots,X_n \\sim \\Bernoulli(p)$. Тогда\n",
    "$$\n",
    "P(|\\mean{\\boldX} - p| > \\eps) \\le 2e^{-2\\eps^2n}.\n",
    "$$\n",
    "\n",
    "Применительно к рассматриваемой ситуации\n",
    "$$\n",
    "\\beta(p,c) = P_{p}(|\\mean{\\boldX} - p| > c) \\le 2e^{-2c^2n}.\n",
    "$$\n",
    "$$\n",
    "P_I(c) = \\beta(p_0,c) \\le 2e^{-2c^2n} = \\alpha.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='power_function_clt_approx'></a>\n",
    "### Аппроксимация функции мощности с помощью ЦПТ<sup>[toc](#_toc)</sup>\n",
    "\n",
    "\\begin{gather*}\n",
    "\\mean{\\boldX} - p = \\sqrt{\\frac{p(1-p)}{n}} \\underbrace{\\frac{\\sqrt{n}(\\mean{\\boldX} - p)}{\\sqrt{p(1 - p)}}}_{\\sim \\Normal(0, 1)},\\\\\n",
    "\\mean{\\boldX} - p_0 = p - p_0 + \\sqrt{\\frac{p(1-p)}{n}} \\frac{\\sqrt{n}(\\mean{\\boldX} - p)}{\\sqrt{p(1 - p)}} \\xrightarrow[n\\to\\infty]{D} \\Normal\\left(p - p_0, \\frac{p(1-p)}{n}\\right).\n",
    "\\end{gather*}\n",
    "Поэтому можем записать аппроксимацию для функции мощности:\n",
    "\\begin{gather*}\n",
    "\\beta(p,c) = P_{p}(|\\mean{\\boldX} - p_0| > c) = P_{p}(\\mean{\\boldX} - p_0 > c) + P_p(\\mean{\\boldX} - p_0 < -c) \\approx \\\\ \\approx\n",
    "P_{p}\\lp Z > \\sqrt{\\frac{n}{p(1-p)}}(c - p + p_0)\\rp +\n",
    "P_{p}\\lp Z < \\sqrt{\\frac{n}{p(1-p)}}(-c - p + p_0)\\rp =\\\\\n",
    "= 1 - \\Phi\\lp \\sqrt{\\frac{n}{p(1-p)}}(c - p + p_0) \\rp +\n",
    "\\Phi\\lp \\sqrt{\\frac{n}{p(1-p)}}(-c - p + p_0) \\rp.\n",
    "\\end{gather*}\n",
    "\n",
    "Для вероятности ошибки первого рода получаем следующую аппроксимацию:\n",
    "\\begin{gather*}\n",
    "P_I(c) = \\beta(p_0,c) \\approx 2 \\lp 1 - \\Phi\\lp \\sqrt{\\frac{n}{p_0(1-p_0)}}c \\rp \\rp = \\alpha.\n",
    "\\end{gather*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='power_function_various_estimates'></a>\n",
    "### Различные варианты оценки функции мощности $\\beta(p, c)$<sup>[toc](#_toc)</sup>\n",
    "* Точный рассчет:\n",
    "$$\n",
    "\\beta(p, c) = \\Prob_p(|\\mean{\\boldX} - p| > c) =  1 - \\Sum_{k = \\lceil(p - c)n \\rceil}^{\\lfloor(p + c)n\\rfloor} C^k_{n} p^k(1-p)^{n - k}.\n",
    "$$\n",
    "* Неравенство Чебышева:\n",
    "$$\n",
    "\\beta(p, c) \\le \\frac{p(1 - p)}{nc^2}.\n",
    "$$\n",
    "* Неравенство Хёффдинга:\n",
    "$$\n",
    "\\beta(p, c) \\le 2\\exp(-2c^2 n).\n",
    "$$\n",
    "* Асимптотическая оценка:\n",
    "$$\n",
    "\\beta(p, c) \\approx 1 - \\Phi\\lp \\sqrt{\\frac{n}{p(1-p)}}(c - p + p_0) \\rp +\n",
    "\\Phi\\lp \\sqrt{\\frac{n}{p(1-p)}}(-c - p + p_0) \\rp\n",
    "$$\n",
    "\n",
    "Правая часть данных равенств/неравенств по сути можно рассматривать как уровень значимости в зависимости от порога $c$ (но не как размер теста!). Посмотрим на вид функций $\\alpha_{\\text{true}}(c)$, $\\alpha_{\\text{cheb}}(c)$, $\\alpha_{\\text{hoff}}(c)$, $\\alpha_{\\text{norm}}(c)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Построение графиков зависимостей $\\alpha(c)$ для различных способов построения критерия<sup>[toc](#_toc)</sup>\n",
    "\n",
    "TODO: Code refactoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.78         # Параметры распределения\n",
    "n = 50           # Размер выборки\n",
    "gen = scipy.stats.binom(n=1, p=p)\n",
    "X = gen.rvs(size=n, random_state=123) # Выборка из n отсчетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_gen = scipy.stats.binom(n=n, p = p)\n",
    "mean_cdf = mean_gen.cdf(np.arange(n + 1))\n",
    "\n",
    "# Левая и правая границы при отрисовке. Не влиюят на вычисления\n",
    "x_left = 0\n",
    "x_right = 0.4\n",
    "\n",
    "# Осмысленный диапазон значений для порога c\n",
    "c_max = max(p, 1 - p); n_points = 1000; c_step = c_max / n_points\n",
    "c_values = np.linspace(c_step, c_max, n_points)\n",
    "\n",
    "\n",
    "power_function = OrderedDict()\n",
    "power_function['Cheb'] = p * (1 - p) / (n * c_values ** 2)\n",
    "power_function['Hoff'] = 2 * np.exp(-2 * c_values ** 2 * n)\n",
    "power_function['Norm'] = 2 * (1 - scipy.stats.norm.cdf(c_values * np.sqrt(n) / np.sqrt(p * (1 - p))))\n",
    "\n",
    "cn_low_upp_values = []\n",
    "for upper_bound in range(int(np.floor(p * n)), n + 1):\n",
    "    cn_value = upper_bound - p * n\n",
    "    cn_low_upp_values.append((cn_value, +np.inf, upper_bound))\n",
    "\n",
    "for lower_bound in range(0, int(np.ceil(p * n)) + 1):\n",
    "    cn_value = p * n - lower_bound\n",
    "    cn_low_upp_values.append((cn_value, lower_bound, -np.inf))\n",
    "\n",
    "# Слияние границ\n",
    "cn_prev = 0; cn_values = [cn_prev]\n",
    "lowers = [int(np.ceil(p * n))]\n",
    "uppers = [int(np.floor(p * n))]\n",
    "for cn_curr, curr_lower, curr_upper in sorted(cn_low_upp_values):\n",
    "    if cn_curr == cn_prev:\n",
    "        # Значение cn не сместилось\n",
    "        if curr_lower < lowers[-1]:\n",
    "            lowers[-1] = curr_lower\n",
    "        if curr_upper > uppers[-1]:\n",
    "            uppers[-1] = curr_upper\n",
    "    else:\n",
    "        cn_values.append(cn_curr)\n",
    "        cn_prev = cn_curr\n",
    "        if curr_lower < lowers[-1]:\n",
    "            lowers.append(curr_lower)\n",
    "        else:\n",
    "            lowers.append(lowers[-1])\n",
    "        if curr_upper > uppers[-1]:\n",
    "            uppers.append(curr_upper)\n",
    "        else:\n",
    "            uppers.append(uppers[-1])\n",
    "lowers = np.array(lowers, dtype=np.int32)\n",
    "uppers = np.array(uppers, dtype=np.int32)\n",
    "cn_values = np.array(cn_values) / n\n",
    "true_size = 1 - (mean_gen.cdf(uppers) - mean_gen.cdf(lowers - 1))\n",
    "\n",
    "\n",
    "colors = {'Cheb': 'r', 'Hoff': 'g', 'Norm': 'b'}\n",
    "plt.figure(figsize=(12, 10))\n",
    "for key in power_function:\n",
    "    plt.plot(c_values, power_function[key], color=colors[key], zorder=2, label=key)\n",
    "plt.step(cn_values, true_size, where='post', color='m', zorder=2, label='True')\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "plt.xlim([x_left, x_right])\n",
    "plt.xlabel(r'critical value, $c$')\n",
    "plt.ylabel(r'test level, $\\alpha$')\n",
    "plt.title('Test level vs critical value')\n",
    "plt.legend()\n",
    "plt.grid(which='both', linestyle=':');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, в данном случае истинная зависимость $\\alpha_{\\text{true}}$ ступенчая, что связано с дискретностью достижимых значений размера теста: не все значения $\\alpha$ из интервала (0,1) достигаются при переборе всевозможных порогов $c \\ge 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.34                    # Запросим тест вот такого размера\n",
    "c_alpha_values = OrderedDict()  # А теперь найдем пороги, позволяющие достигнуть теста максимального размера, но не более alpha\n",
    "c_alpha_values['Cheb'] = np.sqrt(p * (1 - p) / (n * alpha))\n",
    "c_alpha_values['Hoff'] = np.sqrt(1 / (2 * n) * np.log(2 / alpha))\n",
    "c_alpha_values['Norm'] = np.sqrt(p * (1 - p) / n) * scipy.stats.norm.ppf(1 - alpha / 2)\n",
    "c_alpha_values['True'] = cn_values[np.searchsorted((true_size < alpha).astype(np.int32), alpha, side='left')]\n",
    "real_test_sizes = {}\n",
    "\n",
    "for test_type, c_alpha_value in c_alpha_values.items():\n",
    "    c_value_index = np.searchsorted(cn_values, c_alpha_value, side='left')\n",
    "    if (c_alpha_value < cn_values[c_value_index]) & (cn_values[c_value_index - 1] <= c_alpha_value):\n",
    "        real_test_size = true_size[c_value_index - 1]\n",
    "    elif (c_alpha_value < cn_values[c_value_index + 1]) & (cn_values[c_value_index] <= c_alpha_value):\n",
    "        real_test_size = true_size[c_value_index]\n",
    "    real_test_sizes[test_type] = real_test_size\n",
    "    print('Power function type \"{}\": c_value = {}, requested size = {}, real size = {}.'.format(\n",
    "        test_type, c_alpha_value, alpha, real_test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {'Cheb': 'r', 'Hoff': 'g', 'Norm': 'b', 'True': 'm'}\n",
    "plt.figure(figsize=(12, 10))\n",
    "for key in power_function:\n",
    "    plt.plot(c_values, power_function[key], color=colors[key], zorder=2, label=key)\n",
    "plt.step(cn_values, true_size, where='post', color='m', zorder=2, label='True')\n",
    "\n",
    "plt.plot([0, 1], [alpha, alpha], color='k', linestyle='--', zorder=2, label='requested size')\n",
    "for test_type, c_alpha_value in c_alpha_values.items():\n",
    "    plt.plot([c_alpha_value, c_alpha_value], [0, 1], linestyle='--', linewidth=1.5, \n",
    "             color=colors[test_type], zorder=2)\n",
    "    real_test_size = real_test_sizes[test_type]\n",
    "    plt.plot([0, 1], [real_test_size, real_test_size], linestyle=':', linewidth=1.5, \n",
    "             color=colors[test_type], zorder=2)\n",
    "\n",
    "plt.ylim(0, 1); plt.xlim([x_left, x_right])\n",
    "plt.xlabel(r'$c$'); plt.ylabel(r'$\\alpha$'); plt.title('Test size vs critical value')\n",
    "plt.legend()\n",
    "plt.grid(which='both', linestyle=':');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "n_errors = defaultdict(int)\n",
    "n_runs = 100000\n",
    "\n",
    "for n_run in tqdm(range(n_runs)):\n",
    "    test_statistic = abs(np.mean(gen.rvs(n, random_state=n_run)) - p)\n",
    "    for test_type in c_alpha_values:\n",
    "        n_errors[test_type] += int(test_statistic > c_alpha_values[test_type] + 1e-8) # Это 1e-8 важна для \n",
    "for test_type in c_alpha_values:\n",
    "    print('Test type = \"{}\", requested size = {}, real_size = {}, experimental size = {}'.format(\n",
    "    test_type, alpha, real_test_sizes[test_type], n_errors[test_type] / n_runs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Критерий Вальда<sup>[toc](#_toc)</sup>\n",
    "TODO\n",
    "\n",
    "#### Критерий отношения правдоподобий<sup>[toc](#_toc)</sup>\n",
    "TODO\n",
    "\n",
    "#### Критерий хи-квадрат<sup>[toc](#_toc)</sup>\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='test_wald'></a>\n",
    "# Критерий Вальда<sup>[toc](#_toc)</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='test_wald_theory'></a>\n",
    "## Теория<sup>[toc](#_toc)</sup>\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='test_wald_tasks'></a>\n",
    "## Задачи<sup>[toc](#_toc)</sup>\n",
    "* [Задача 1. Подбрасывание монетки](#hypo_binomial_task1)\n",
    "* [Задача 2. Сравнение двух алгоритмов предсказания](#hypo_examples_comp)\n",
    "* [Задача 6](#test_permutation_task1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='test_llr'></a>\n",
    "# Критерий отношения правдоподобий<sup>[toc](#_toc)</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='test_llr_theory'></a>\n",
    "## Теория<sup>[toc](#_toc)</sup>\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='test_llr_tasks'></a>\n",
    "## Задачи<sup>[toc](#_toc)</sup>\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='test_np'></a>\n",
    "# Критерий Неймана-Пирсона<sup>[toc](#_toc)</sup>\n",
    "Предположим, что  мы тестируем гипотезу $H_0\\colon \\theta = \\theta_0$ против альтернативы $H_1\\colon \\theta = \\theta_1$. Пусть\n",
    "\\begin{gather*}\n",
    "T = \\frac{L(\\boldX;\\theta_1)}{L(\\boldX;\\theta_0)} = \\frac{\\Prod_{i=1}^n f(X_i;\\theta_1)}{\\Prod_{j=1}^n f(X_j;\\theta_0)}.\n",
    "\\end{gather*}\n",
    "Предположим, что гипотеза $H_0$ отбрасывается, если $T > k$. Если выбрать такое значение $k(\\alpha)$, что размер теста $\\Prob_{\\theta_0}(T > k) = \\alpha$, тогда данный тест является наиболее мощным тестом размера $\\alpha$. Т.е. среди всех тестов размера $\\alpha$, данный тест обладает наибольшим значением $\\beta(\\theta_1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='test_np_tasks'></a>\n",
    "## Задачи<sup>[toc](#_toc)</sup>\n",
    "* [Задача 1](#test_np_task1)\n",
    "* [Задача 2](#test_np_task2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='test_chi2'></a>\n",
    "# Критерий хи-квадрат<sup>[toc](#_toc)</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='test_chi2_theory'></a>\n",
    "## Теория<sup>[toc](#_toc)</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='test_chi2_simple'></a>\n",
    "### Критерий хи-квадрат для проверки простой гипотезы $H_0$<sup>[toc](#_toc)</sup>\n",
    "Критерий Пирсона предназначен для проверки мультиномиального распреления. Пусть вектор $\\boldX = (X_1,\\dots,X_m)$ имеет мультиномиальное распределение с параметрами $(n, \\boldp)$, где $\\boldp = (p_1, \\dots, p_m)$, т.е.\n",
    "$$\n",
    "P(\\boldX = (n_1,\\dots,n_m)) = \\frac{n!}{n_1!\\dots n_m!} p_1^{n_1}\\dots p_m^{n_m}.\n",
    "$$\n",
    "Требуется построить критерий для различения гипотез:\n",
    "$$\n",
    "H_0\\colon \\boldp = \\boldp_0 \\text{ против } H_1 \\colon \\boldp \\neq \\boldp_0,\n",
    "$$\n",
    "где $\\boldp_0 = (p_{01}, \\dots, p_{0m})$.\n",
    "\n",
    "**Статистика хи-квадрта ($\\chi^2$-статистика)** имеет вид\n",
    "$$\n",
    "T_{\\chi^2}(\\boldX) = \\Sum_{j=1}^m\\frac{(X_j - np_{0j})^2}{np_{0j}} = \\Sum_{j=1}^m\\frac{(X_j - E_j)^2}{E_j},\n",
    "$$\n",
    "где $E_j = \\Exp(X_j) = np_{0j}$ &mdash; мат. ожидание значения $X_j$ при условии справедливости гипотезы $H_0$.\n",
    "\n",
    "**Если гипотеза $H_0$ верна, то $T \\xrightarrow[n\\to\\infty]{P} \\chi^2_{m-1}$. Таким образом, $\\alpha$-тест имеет вид: если $T > \\chi^2_{m-1,\\alpha}$, то гипотеза $H_0$ отклоняется. При этом $\\text{p-value}(\\boldX) = \\Prob(\\chi^2_{m-1} > T(\\boldx))$, где $\\boldx$ &mdash; конкретная реализация $\\boldX$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='test_chi2_complex'></a>\n",
    "### Критерий хи-квадрат для проверки сложной гипотезы $H_0$<sup>[toc](#_toc)</sup>\n",
    "\n",
    "Пусть дана выборка $\\boldX = \\{X_1,\\dots,X_n\\}$. Требуется проверить гипотезу о том, что выборка порождена распределением из некоторого параметрического семейства дискретных распределений $\\mathcal{F} = \\{F_\\theta \\colon \\theta \\subseteq \\Theta\\}$, где $\\Theta \\subseteq \\RR^r$. Пусть $A = \\{a_1,\\dots, a_m\\}$ &mdash; множество возможных значений ($m \\leq \\infty$). Обозначим $P(X = a_j) = p_j$.\n",
    "Основная гипотеза имеет вид:\n",
    "$$\n",
    "H_0 \\colon p_j = p_{0j}(\\theta),\\quad \\theta \\in \\Theta \\subseteq \\RR^r, \\quad r < m - 1.\n",
    "$$\n",
    "Гипотеза $H_0$ является сложной, так как содержит на одно распределение, а семейство распределений.\n",
    "\n",
    "* **Статистика хи-квадрат для проверки сложной парамерической гипотезы имеет вид**\n",
    "$$\n",
    "T_{\\chi^2}(\\boldX) = \\Sum_{j=1}^m \\frac{(n_j - n p_{0j}(\\hat{\\theta}))^2}{np_{0j}(\\hat{\\theta})},\\quad n_j = \\Sum_{i=1}^n I[X_i = a_i], \\quad \\hat{\\theta} = \\argmax_{\\theta \\in \\Theta} \\Prod_{j=1}^m (p_{0j}(\\theta))^{n_j}.\n",
    "$$\n",
    "т.е. $n_j$ &mdash; количество испытаний с исходом $a_j$, а $\\hat{\\theta}$ &mdash; оценка максимума правдоподобия.\n",
    "* **Если гипотеза $H_0$ верна, то**\n",
    "$$\n",
    "T_{\\chi^2}(\\boldX) \\xrightarrow[n\\to\\infty]{D} \\chi^2_{m - 1 - r}.\n",
    "$$\n",
    "* **Критерий размера $\\alpha$ имеет вид: если $T_{\\chi^2}(\\boldX) > \\chi^2_{m - 1 - r, \\alpha}$, то гипотеза $H_0$ отклоняется.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='test_chi2_tasks'></a>\n",
    "## Задачи<sup>[toc](#_toc)</sup>\n",
    "* [Задача 1](#test_chi2_task1)\n",
    "* [Задача 2](#test_chi2_task2)\n",
    "* [Задача 3](#test_chi2_task3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='test_kolmogorov'></a>\n",
    "# Критерий Колмогорова<sup>[toc](#_toc)</sup>\n",
    "* [Теория](#test_kolmogorov_theory)\n",
    "* [Примеры](#test_kolmogorov_examples)\n",
    "* [Задачи](#test_kolmogorov_tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='test_kolmogorov_theory'></a>\n",
    "## Теория<sup>[toc](#_toc)</sup>\n",
    "\n",
    "Дана выборка $\\boldX = \\{X_1,\\dots,X_k\\} \\sim F$. Эмпирическая функция распределения имеет вид:\n",
    "$$\n",
    "\\hat{F}_n(x) = \\frac{1}{n} \\Sum_{i=1}^{n} I[X_i < x].\n",
    "$$\n",
    "Обозначим\n",
    "$$\n",
    "D_n = \\sup_{x} |\\hat{F}_n(x) - F(x)|.\n",
    "$$\n",
    "\n",
    "Если гипотеза $H_0$ верна, то\n",
    "$$\n",
    "\\lim_{n\\to\\infty} P(\\sqrt{n} D_n < x) = K(x),\n",
    "$$\n",
    "где\n",
    "$$\n",
    "K(x) = \\Sum_{j=-\\infty}^{+\\infty}(-1)^{j}e^{-2j^2x^2}I[x \\ge 0].\n",
    "$$\n",
    "Функция $K(x)$ &mdash; функция распределения Колмогорова.\n",
    "\n",
    "На практике для вычисления $D_n$ можно воспользоваться следующей формулой:\n",
    "$$\n",
    "D_n = \\sqrt{n} \\max\\left\\{\\frac{k}{n} - F(X_{(k)}, F(X_{(k)}) - \\frac{k - 1}{n}\\right\\}.\n",
    "$$\n",
    "\n",
    "**Критерий Колмогорова: если $\\sqrt{n}D_n > K^{-1}(1 - \\alpha)$, то гипотеза $H_0$ отклоняется.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='test_kolmogorov_examples'></a>\n",
    "## Примеры<sup>[toc](#_toc)</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример 1\n",
    "Сгенерируем выборку $\\boldX \\sim F = \\Normal(\\mu_1, \\sigma_1^2)$ и проверим гипотезу $H_0\\colon F = \\Normal(\\mu_2,\\sigma_2^2)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "random_state = 2\n",
    "alpha = 0.05\n",
    "\n",
    "real_gen = scipy.stats.norm(loc=0., scale=1.)\n",
    "samples = real_gen.rvs(size=n_samples, random_state=random_state)\n",
    "samples = np.sort(samples)\n",
    "\n",
    "tested_gen = scipy.stats.norm(loc=0., scale=1.)\n",
    "tested_cdfs = tested_gen.cdf(samples)\n",
    "\n",
    "a = np.abs(np.arange(1, n_samples + 1, dtype=np.float64) / n_samples - tested_cdfs)\n",
    "b = np.abs(np.arange(n_samples, dtype=np.float64) / n_samples - tested_cdfs)\n",
    "D = np.max(np.maximum(a, b))\n",
    "T = np.sqrt(n_samples) * D\n",
    "c = scipy.stats.kstwobign.ppf(1 - alpha)\n",
    "p_value = 1 - scipy.stats.kstwobign.cdf(T)\n",
    "print(f'T = {T}')\n",
    "print(f'c = {c}')\n",
    "print(f'p-value = {p_value}')\n",
    "if p_value > alpha:\n",
    "    print('Preserving H0')\n",
    "else:\n",
    "    print('Rejecting H0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример 2. Importance sampling<sup>[toc](#_toc)</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "alpha = 0.05\n",
    "random_state = 325\n",
    "source_gen = scipy.stats.norm(loc=1., scale=2.)\n",
    "target_gen = scipy.stats.norm(loc=1., scale=2.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importance sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_samples = source_gen.rvs(size=n_samples, random_state=random_state)\n",
    "log_weights = target_gen.logpdf(source_samples) - source_gen.logpdf(source_samples)\n",
    "log_weights -= np.max(log_weights)\n",
    "weights = np.exp(log_weights) / np.sum(np.exp(log_weights))\n",
    "\n",
    "gen = np.random.RandomState(random_state + 1)\n",
    "# Such sampling strategy is not very good in results if test's false failing when H0 is correct\n",
    "# It is better to use deterministic sampling strategy\n",
    "target_samples = gen.choice(source_samples, size=n_samples, p=weights)\n",
    "del gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_samples = np.sort(target_samples)\n",
    "target_cdfs = target_gen.cdf(target_samples)\n",
    "a = np.abs(np.arange(1, n_samples + 1, dtype=np.float64) / n_samples - target_cdfs)\n",
    "b = np.abs(np.arange(n_samples, dtype=np.float64) / n_samples - target_cdfs)\n",
    "D = np.max(np.maximum(a, b))\n",
    "T = np.sqrt(n_samples) * D\n",
    "c = scipy.stats.kstwobign.ppf(1 - alpha)\n",
    "p_value = 1 - scipy.stats.kstwobign.cdf(T)\n",
    "print(f'T = {T}')\n",
    "print(f'c = {c}')\n",
    "print(f'p-value = {p_value}')\n",
    "if p_value > alpha:\n",
    "    print('Preserving H0')\n",
    "else:\n",
    "    print('Rejecting H0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='test_kolmogorov_tasks'></a>\n",
    "## Задачи<sup>[toc](#_toc)</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='test_permutation'></a>\n",
    "# Критерий перестановок<sup>[toc](#_toc)</sup>\n",
    "* [Теория](#test_permutation_theory)\n",
    "    * [Формулировка критерия перестановок](#test_permutation_def)\n",
    "    * [Пример 1. Равенство нормальных распределений](#test_permutation_examle1)\n",
    "* [Задачи](#test_permutation_tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='test_permutation_theory'></a>\n",
    "## Теория<sup>[toc](#_toc)</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть $\\boldX =\\{X_1,\\dots,X_n\\} \\sim F_X$ и $\\boldY =\\{Y_1,\\dots,Y_m\\} \\sim F_Y$. Обозначим через $\\boldZ = (Z_1,\\dots,Z_N)$ сконкатенированную выборку $(X_1,\\dots,X_n,Y_1,\\dots,Y_m)$, $N = m + n$. Требуется протестировать гипотезу $H_0 \\colon F_X = F_Y = F_Z$.\n",
    "\n",
    "Пусть $T(\\boldZ) = T(\\boldX,\\boldY) = T(X_1,\\dots,X_n,Y_1,\\dots,Y_m)$ &mdash; некоторая тестовая статистика. Например, в качестве такой статистики может выступать\n",
    "$$\n",
    "T(\\boldX,\\boldY) = |\\overline{\\boldX} - \\overline{\\boldY}|.\n",
    "$$\n",
    "\n",
    "Теоретическая формулировка критериев обычна основана на том, что при справедливости гипотезы $H_0$ статистика критерия $T$ имеет некоторое заданное распределение. Правда в отличие от других критериев, когда для $T$ существует некоторое предельное распределение при увеличении размера выборки, в случае критерия перестановок стоится оценка $\\hat{F}_T(t)$ истинной функции распределения $F_T(t)$ для конкретного размера выборки. Собственно, далее попытаемся получить какую-нибудь оценку функции распредления $F_T(t)$ при условии справедливости гипотезы $H_0$, т.е. когда $F_X = F_Y = F_Z$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Оценка распределения $F_T(t)$<sup>[toc](#_toc)</sup>\n",
    "\n",
    "Допустим, нам известно распределение $F_Z$, и мы можем генерировать выборки из него. При этом наша цель состоит в построении оценки для функции распределения $F_{T}(t)$. Тогда мы могли бы поступить следующим образом:\n",
    "* Генерируем выборки $\\boldZ_1,\\dots,\\boldZ_M$, где $\\boldZ \\sim F_Z$.\n",
    "* Подсчитываем значения $T_1,\\dots,T_M$ статистики $T(\\boldZ)$ на этих выборках.\n",
    "* Строим эмпирическую функции $\\hat{F}_{T}(t)$ по выборке $\\boldT = (T_1,\\dots,T_{M})$:\n",
    "$$\n",
    "\\hat{F}_T(t) = \\frac{1}{M} \\Sum_{i=1}^{M} I[T_i < t].\n",
    "$$\n",
    "\n",
    "Понятно, что на практике первый этап данной процедуры невозможен в силу того, что $F_Z$ неизвестна. Но мы можем построить её э.ф.р., так как нам известна выборка $\\boldZ = (Z_1,\\dots,Z_{N}) = (X_1,\\dots,X_n,Y_1,\\dots,Y_m)$:\n",
    "$$\n",
    "\\hat{F}_Z(z) = \\frac{1}{N}\\Sum_{i=1}^N I[Z_i < z]\n",
    "$$\n",
    "Поэтому будем генерировать новые выборки $\\boldZ_1,\\dots,\\boldZ_M$ из неё. Возможные значения новых выборок &mdash; это всевозможные перестановки известной выборки $\\boldZ$, которые обозначим $\\boldZ_{1}^{*},\\dots,\\boldZ_{N!}^{*}$ причем все эти выборки равновероятны:\n",
    "$$\n",
    "P(\\boldZ_{i}^{*}) = \\frac{1}{N!}, \\quad i \\in \\{1,\\dots, N!\\}.\n",
    "$$\n",
    "Множество возможных значений $T(\\boldZ)$ дискретно с $N!$ возможными значениями, которые обозначим $T_1^*, \\dots, T_{N!}^*$. Истинная функция распределения статистики $T(\\boldZ)$ имеет вид:\n",
    "$$\n",
    "\\tilde{F}_T(t) = \\frac{1}{N!} \\Sum_{i=1}^{N!} I[T_i^* < t].\n",
    "$$\n",
    "Поэтому с ростом  с ростом числа генерируемых выборок $M$, а точнее при $M \\gg N!$, э.ф.р. по значениям $T_1,\\dots,T_M$ приблизится к данной функции. Но тогда и генерировать эти $M$ выборок из $\\hat{F}_Z$ незачем, а достаточно сразу смотреть на предельную $\\tilde{F}_T(t)$.\n",
    "\n",
    "Далее возникает вопрос, насколько правомерна замена $F_Z$ на $\\hat{F}_Z$? Тут уже есть результат, утверждающий, что \n",
    "$\\hat{F}_Z$ сходится к $F_Z$ равномерно с увеличением размера выборки $N$. При этом можно показать, хотя здесь этого и не делаем, что $\\hat{F}_T(t)$ будет сходиться к $F_T(t)$:\n",
    "$$\n",
    "\\hat{F}_T(t) = \\frac{1}{N!} \\Sum_{i=1}^{N!} I[T_i^* < t] \\rightarrow F_T(t).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Оценка p-value<sup>[toc](#_toc)</sup>\n",
    "Предположим, что $\\hat{F}_T(t) \\approx F_T(t)$. Тогда для конкретных реализаций выборок $\\boldx$ и $\\boldy$ получаем, что p-value можно оценить следующим образом:\n",
    "$$\n",
    "\\text{p-value}(\\boldx, \\boldy) = P_{H_0}(T(\\boldX,\\boldY) > T(\\boldx, \\boldy)) = 1 - F_T(T(\\boldx,\\boldy)) \\approx 1 - \\hat{F}_T(T(\\boldx,\\boldy)).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='test_permutation_def'></a>\n",
    "### Формулировка критерия перестановок<sup>[toc](#_toc)</sup>\n",
    "* Генерируем все $N!$ перестановок выборки $\\boldZ = (\\boldX,\\boldY)$\n",
    "* Для перестановки $\\boldZ_i^*$ считаем значение статистики $T_i^* = T(\\boldX_i^*)$\n",
    "* Вычисляем приближенное значение p-value:\n",
    "$$\n",
    "\\text{p-value} = \\frac{1}{N!} \\Sum_{i=1}^{N!} I[T_i^* > T(\\boldX,\\boldY)].\n",
    "$$\n",
    "\n",
    "\n",
    "В некоторых случаях количество перестановок можно уменьшить. Например, в случае статистики\n",
    "$$\n",
    "T(\\boldX,\\boldY) = |\\mean{\\boldX} - \\mean{\\boldY}|\n",
    "$$\n",
    "достаточно сгенерировать $C^{n}_{n+m} = \\frac{(n + m)!}{n!m!}$ разбиений элементов $(X_1,\\dots,X_n,Y_1,\\dots,Y_m)$ на группы размера $n$ и $m$. Каждому разбиению соответствует $n!m!$ перестановок элементов внутри групп, но каждая такая перестановка дает одно и то же значение статистики, поэтому генерировать все перестановки не нужно.\n",
    "\n",
    "В любом случае, если требуемое количество генерируемых перестановок слишком велико, то можно воспользоваться приближенной процедурой:\n",
    "* Генерируем $B$ ($B < N!$) перестановок выборки $\\boldZ = (\\boldX,\\boldY)$\n",
    "* Для перестановки $\\boldZ_i^*$ считаем значение статистики $T_i^* = T(\\boldX_i^*)$ \n",
    "* Вычислим приближенное значение $\\text{p-value}$:\n",
    "$$\n",
    "\\text{p-value} = \\frac{1}{B} \\Sum_{i=1}^B I[T_i^* > T(\\boldX,\\boldY)].\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='test_permutation_examle1'></a>\n",
    "### Пример 1. Равенство нормальных распределений<sup>[toc](#_toc)</sup>\n",
    "Пусть $\\boldX = \\{X_1,\\dots,X_n\\} \\sim \\Normal(\\mu_1,\\sigma^2)$, $\\boldY = \\{Y_1,\\dots,Y_m\\} \\sim \\Normal(\\mu_2,\\sigma^2)$. Требуется построить критерий перестановок для проверки $H_0 \\colon \\mu_1 = \\mu_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Решение.**\n",
    "Будем рассматривать статистику \n",
    "$$\n",
    "T(\\boldX,\\boldY) = |\\overline{\\boldX} - \\overline{\\boldY}|.\n",
    "$$\n",
    "\n",
    "Сначала решим следующую подзадачу: найдем распределение случайной величины $T(\\boldX,\\boldY) = |\\mean{\\boldX} - \\mean{\\boldY}|$, где $\\boldX \\sim \\Normal(\\mu_1,\\sigma_1^2)$, $\\boldY \\sim \\Normal(\\mu_2,\\sigma_2^2)$,\n",
    "Так как распределения нормальные, то\n",
    "$$\n",
    "\\overline{\\boldX} - \\overline{\\boldY} \\sim \\Normal\\left(\\mu_1 - \\mu_2, \\frac{\\sigma_1^2}{n} + \\frac{\\sigma_2^2}{m}\\right),\n",
    "$$\n",
    "т.е. распределение статистики &mdash; распределение модуля нормальной случайной величины."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим параметры распределения модуля нормальной случайной величины. Пусть $X \\sim \\Normal(0, \\sigma^2)$. Тогда\n",
    "\\begin{align*}\n",
    "&p_{|X|}(x) = \\frac{2}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{x^2}{2\\sigma^2}} I[x \\ge 0],\\\\\n",
    "&F_{|X|}(x) = 2 \\Phi(x),\\\\\n",
    "&E[|X|] = \\Int_{0}^{+\\infty} \\frac{2x}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{x^2}{2\\sigma^2}} dx = \\frac{2}{\\sqrt{2\\pi\\sigma^2}} \\Int_{0}^{+\\infty} e^{-\\frac{z}{\\sigma^2}} dz = \\sqrt{\\frac{2\\sigma^2}{\\pi}},\\\\\n",
    "&E[X^2] = \\Int_{0}^{+\\infty} \\frac{2x^2}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{x^2}{2\\sigma^2}} dx =\n",
    "\\Int_{-\\infty}^{+\\infty} \\frac{x^2}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{x^2}{2\\sigma^2}} dx = \\sigma^2,\\\\\n",
    "&\\Var[|X|] = \\sigma^2 \\frac{\\pi - 2}{\\pi}.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае справедливости гипотезы $H_0$ $\\mu_1 = \\mu_2 = \\mu$, т.е. при $\\boldX \\sim \\Normal(\\mu,\\sigma_1^2)$ и $\\boldY \\sim \\Normal(\\mu,\\sigma_2^2)$ для теоретических значений параметров распределения $T(\\boldX,\\boldY)$ получаем:\n",
    "\\begin{align*}\n",
    "&p_{T(\\boldX,\\boldY)}(x) = \\frac{2}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x - \\mu)^2}{\\sigma^2}\\right),\\quad \\mu = 0, \\quad \\sigma^2 = \\frac{\\sigma_1^2}{n} + \\frac{\\sigma_2^2}{m}, \\\\\n",
    "&\\Exp[T(\\boldX,\\boldY)] = p[|\\overline{\\boldX} - \\overline{\\boldY}|] = \\sqrt{\\frac{2}{\\pi}\\left(\\frac{\\sigma_1^2}{n} + \\frac{\\sigma_2^2}{m}\\right)},\\\\\n",
    "&\\Exp[T(\\boldX,\\boldY)^2] = \\Exp[|\\overline{\\boldX} - \\overline{\\boldY}|^2] = \\frac{\\sigma_1^2}{n} + \\frac{\\sigma_2^2}{m},\\\\\n",
    "&\\Var[T(\\boldX,\\boldY)] = \\Var[|\\overline{\\boldX} - \\overline{\\boldY}|] = \\left(\\frac{\\sigma_1^2}{n} + \\frac{\\sigma_2^2}{m}\\right) \\frac{\\pi - 2}{\\pi}.\\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сгенерируем выборки $\\boldX$ и $\\boldY$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 4\n",
    "\n",
    "mu1 = 5\n",
    "sigma1 = 1\n",
    "n_samples1 = 9\n",
    "\n",
    "mu2 = 5\n",
    "sigma2 = 1\n",
    "n_samples2 = 9\n",
    "\n",
    "gen1 = scipy.stats.norm(loc=mu1, scale=sigma1)\n",
    "gen2 = scipy.stats.norm(loc=mu2, scale=sigma2)\n",
    "X = gen1.rvs(size=n_samples1, random_state=random_state)\n",
    "Y = gen2.rvs(size=n_samples2, random_state=random_state + 1)\n",
    "Z = np.concatenate([X, Y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Найдем теоретические и практические оценки параметров распределения статистики $T(\\boldX,\\boldY)$.**\n",
    "Заметим, что ниже генерируются только $\\frac{(n+m)}{!n!m!}$ значений статистики $T$, а не все $(n + m)!$ возможных, так как для каждой перестановки существует $n!m!$ перестановок (включая идентичную), которые получаются перестановками внутри групп $Z_1,\\dots,Z_n$ и $Z_{n+1},\\dots,Z_{n + m}$, и на которых статистика $T$ имеет то же самое значение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from itertools import combinations\n",
    "\n",
    "n_samples = n_samples1 + n_samples2\n",
    "statistics = []\n",
    "for subset in combinations(range(n_samples), n_samples1):\n",
    "    S_X = np.sum(Z[np.array(subset)])\n",
    "    S_Y = np.sum(Z) - S_X\n",
    "    S_X /= n_samples1\n",
    "    S_Y /= n_samples2\n",
    "    T = np.abs(S_X - S_Y)\n",
    "    statistics.append(T)\n",
    "assert len(statistics) == math.factorial(n_samples) / math.factorial(n_samples1) / math.factorial(n_samples2)\n",
    "print(f'Number of Ts: {len(statistics)}')\n",
    "\n",
    "X_mean_var_estimated = np.std(X) / n_samples1  # Variance of mean(X)\n",
    "Y_mean_var_estimated = np.std(Y) / n_samples2  # Variance of mean(Y)\n",
    "\n",
    "T_mean_theoretical = np.sqrt(2 * (sigma1**2 / n_samples1 + sigma2**2 / n_samples2) / np.pi)\n",
    "T_var_theoretical = (sigma1**2 / n_samples1 + sigma2**2 / n_samples2) * (np.pi - 2) / np.pi \n",
    "print('theoretical: T_mean = {:4f}, T_var = {:.4f}'.format(\n",
    "    T_mean_theoretical, T_var_theoretical))\n",
    "\n",
    "T_mean_estimated = np.mean(statistics)\n",
    "T_var_estimated = np.var(statistics, ddof=0)\n",
    "print('estimated: T_mean = {:4f}, T_var = {:.4f}'.format(\n",
    "    T_mean_estimated, T_var_estimated))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Построим теоретические и практические оценки распределения статитсики $T(\\boldX,\\boldY)$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# 1. Plotting CDFs\n",
    "ax = axarr[0]\n",
    "statistics = np.sort(statistics)\n",
    "ecdf_values = np.arange(len(statistics), dtype=np.float64) / len(statistics)\n",
    "ax.step(statistics, ecdf_values, where='post', color='b', label='estimated')\n",
    "ax.plot(statistics, 2 * (scipy.stats.norm.cdf(\n",
    "        statistics, loc=0., scale=np.sqrt(sigma1**2 / n_samples1 + sigma2**2 / n_samples2)) - 0.5),\n",
    "        color='r', label='real')\n",
    "ax.grid(which='both', linestyle=':', alpha=0.5);\n",
    "ax.set_title('Real and estimated F_T')\n",
    "ax.set_xlabel('t')\n",
    "ax.set_ylabel('F_T(t)')\n",
    "ax.legend();\n",
    "\n",
    "\n",
    "# 2. Plotting PDFs\n",
    "ax = axarr[1]\n",
    "\n",
    "# Theoretical pdf of T(\\boldX,\\boldY)\n",
    "xs = np.linspace(np.min(statistics), np.max(statistics), 1000)\n",
    "pdfs = 2 * scipy.stats.norm.pdf(\n",
    "    xs, loc=0, scale=np.sqrt(sigma1**2 / n_samples1 + sigma2**2 / n_samples2))\n",
    "ax.plot(xs, pdfs, color='r')\n",
    "\n",
    "# Estimated histogram estimated for pdf of T(\\boldX, \\boldY)\n",
    "ax.hist(statistics, density=True, color='b', edgecolor='k', alpha=0.5);\n",
    "ax.grid(which='both', linestyle=':', alpha=0.5);\n",
    "ax.set_title('Real and estimated p_T')\n",
    "ax.set_xlabel('t')\n",
    "ax.set_ylabel('p_T(t)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При $\\mu_1 = \\mu_2 = \\mu$ и $\\sigma_1^2 = \\sigma_2^2 = \\sigma^2$ (т.е. при гипотезе $H_0$) функция распределения $F_T(t)$ её эмпирическая оценка $\\hat{F}_T(t)$ должны получиться довольно близкими, что демонстрирует возможность использовать $\\hat{F}_{T}(t)$ для подсчета p-value:\n",
    "$$\n",
    "\\text{p-value}(\\boldx,\\boldy) = P(T(\\boldX,\\boldY) > T(\\boldx,\\boldy)) = 1 - F_{T}(T(\\boldx,\\boldy)) \\approx 1 - \\hat{F}_{T}(T(\\boldx,\\boldy)) = \\frac{1}{N!} \\Sum_{i=1}^{N!} I[T_i > T_1].\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic = np.abs(np.mean(X) - np.mean(Y))\n",
    "p_value = np.mean(np.array(statistics) > statistic)\n",
    "print('p-value: {}'.format(p_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='test_permutation_tasks'></a>\n",
    "## Задачи<sup>[toc](#_toc)</sup>\n",
    "* [Задача 1](#test_permutation_task1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='tasks'></a>\n",
    "# Задачи<sup>[toc](#_toc)</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='hypo_binomial_task1'></a>\n",
    "## Задача 1 (Подбрасывание монетки)<sup>[toc](#_toc)</sup>\n",
    "В результате эксперимента с подбрасыванием монетки были 922 раза выпал \"орел\" и 997 раз выпала \"решка\". Протестируйте гипотезу о том, что монетка симметрична, на уровне значимости 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = 922\n",
    "Y = 997\n",
    "p0 = 0.5\n",
    "alpha = 0.05\n",
    "\n",
    "N = X + Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Тест Вальда<sup>[toc](#toc)</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_estimated = X / N\n",
    "p_var_estimated = p_estimated * (1 - p_estimated) / N\n",
    "w_statistic = abs(X / N - p0) / np.sqrt(p_var_estimated)\n",
    "p_value = 2 * (1 - scipy.stats.norm.cdf(w_statistic))\n",
    "print(f'estimated p: {p_estimated}')\n",
    "print(f'estimated variance of p: {p_var_estimated}')\n",
    "print(f'Wald statistic value: {w_statistic}')\n",
    "print(f'p_value for Wald test: {p_value}')\n",
    "if p_value < alpha:\n",
    "    print('result: H0 rejected')\n",
    "else:\n",
    "    print('result: H0 preserved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим доверительные интервалы для уровней $1 - \\alpha$ и $1 - \\text{p-value}(\\boldX)$. Заметим, что по определению $\\text{p-value}$ доверительный интервал уровня $1 - \\text{p-value}(\\boldX)$ должен \"поймать\" ожидаемое значение $p_0 = 0.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = p_value\n",
    "\n",
    "z_alpha = scipy.stats.norm.ppf(1 - alpha / 2)\n",
    "z_beta = scipy.stats.norm.ppf(1 - beta / 2)\n",
    "print(z_alpha, z_beta)\n",
    "\n",
    "p_std = np.sqrt(p_var_estimated)\n",
    "p_alpha_conf = (p_estimated - z_alpha * p_std, p_estimated + z_alpha * p_std)\n",
    "p_beta_conf = (p_estimated - z_beta * p_std, p_estimated + z_beta * p_std)\n",
    "\n",
    "print('confidence interval for alpha = {}: {}'.format(int((1 - alpha) * 100), p_alpha_conf))\n",
    "print('confidence interval for beta = {}: {}'.format(int((1 - beta) * 100), p_beta_conf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Критерий хи-квадрат<sup>[toc](#toc)</sup>\n",
    "Статистика хи-квадрат в рассматриваемом случае имеет вид\n",
    "\\begin{gather*}\n",
    "T_{\\chi^2}(\\boldX) = \\frac{(X - p_0N)^2}{p_0 N} + \\frac{(Y - p_1N)^2}{p_1 N} = \\frac{p_1(X - p_0 N)^2 + (Y - p_1 N)^2}{N p_0 p_1} = \\frac{p_1 X^2 - 2 p_0 p_1 X N + p_1 p_0^2N^2 + p_0 Y^2 - 2 p_0 p_1 Y N + p_0p_1^2 N^2}{Np_0(1-p_0)} = \n",
    "\\frac{p_1 X^2 + p_0 Y^2 - 2 p_0 p_1 N^2 + p_0p_1 N^2}{N p_0(1 - p_0)} = \n",
    "\\frac{p_1 X^2 + p_0 (N - X)^2 - 2 p_0 p_1 N^2 + p_0 p_1 N^2}{N p_0(1 - p_0)} =\n",
    "\\frac{p_1 X^2 + p_0 N^2 - 2 p_0 N X + p_0 X^2 - 2 p_0 p_1 N^2 + p_0 p_1 N^2}{N p_0(1 - p_0)} = \n",
    "\\frac{X^2 - 2 p_0 NX + p_0^2N^2}{N p_0 (1 - p_0)} = \\frac{(X - p_0 N)^2}{Np_0(1 - p_0)}.\n",
    "\\end{gather*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_statistic = (X - p0 * N) ** 2 / (p0 * N) + (Y - (1 - p0) * N) ** 2 / ((1 - p0) * N)\n",
    "p_value = 1 - scipy.stats.chi2.cdf(x=chi2_statistic, df=1)\n",
    "print('chi2 statistic value:', chi2_statistic)\n",
    "print('p_value for chi2 test:', p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='comparing_prediction_algorithms'></a>\n",
    "## Задача 2. Сравнение двух алгоритмов предсказания<sup>[toc](#_toc)</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\boldX \\sim \\Binomial(n_X, p_X)$, $\\boldY \\sim \\Binomial(n_Y, p_Y)$\n",
    "\n",
    "$$\n",
    "H_0 \\colon p_X = p_Y \\text{ против } H_1 \\colon p_X \\neq p_Y.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нагенерируем данных<sup>[toc](#_toc)</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 3543636\n",
    "tests_number = 10000\n",
    "samples_number = 1500\n",
    "p = 0.12\n",
    "\n",
    "gen = np.random.RandomState(seed)\n",
    "X = gen.binomial(1, p, size=(tests_number, samples_number))\n",
    "Y = gen.binomial(1, p, size=(tests_number, samples_number))\n",
    "print(f'X.shape={X.shape}, Y.shape={Y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Критерий Вальда<sup>[toc](#_toc)</sup>\n",
    "Предположим, что алогоритмы работали на разных исходных данных, так что выборки $\\boldX$ и $\\boldY$ можно считать независимыми.\n",
    "$$\n",
    "T(\\boldX,\\boldY) = |\\overline{\\boldX} - \\overline{\\boldY}|\n",
    "$$\n",
    "\n",
    "Если $\\boldX = \\{X_1,\\dots,X_n\\} \\sim \\Bernoulli(p)$, то для дисперсии выборочного среднего $\\overline{\\boldX}$ и оценки дисперсии $\\overline{\\boldX}$ получаем:\n",
    "$$\n",
    "\\Var_{p}[\\overline{\\boldX}] = \\frac{p(1-p)}{n}, \\quad \\hat{\\Var}_{p}[\\overline{\\boldX}] = \\frac{\\hatp(1-\\hatp)}{n}\n",
    "$$\n",
    "\n",
    "Поэтому для оценки дисперсии $W = \\overline{\\boldX} - \\overline{\\boldY}$ получаем:\n",
    "$$\n",
    "\\hat{\\Var}[W] = \\hat{\\Var}_{p_X}[\\overline{\\boldX}] + \\hat{\\Var}_{p_Y}[\\overline{\\boldY}] = \\frac{\\hatp_X(1-\\hatp_X)}{n_X}+ \\frac{\\hatp_Y(1-\\hatp_Y)}{n_Y}.\n",
    "$$\n",
    "\n",
    "$W$ &mdash; асимптотически нормальная случайная величина."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "\n",
    "p_X_estimates = np.mean(X, axis=1)\n",
    "p_X_var_estimates = np.var(X, axis=1, ddof=0) / samples_number\n",
    "assert p_X_estimates.shape == (tests_number,)\n",
    "\n",
    "p_Y_estimates = np.mean(Y, axis=1)\n",
    "p_Y_var_estimates = np.var(Y, axis=1, ddof=0) / samples_number\n",
    "assert p_Y_estimates.shape == (tests_number,)\n",
    "\n",
    "W_values = (p_X_estimates - p_Y_estimates) / np.sqrt(p_X_var_estimates + p_Y_var_estimates)\n",
    "assert W_values.shape == p_X_estimates.shape\n",
    "\n",
    "z_alpha = scipy.stats.norm.ppf(q=1 - alpha / 2., loc=0, scale=1.)\n",
    "\n",
    "print('Estimated test size: {}'.format(np.mean(np.abs(W_values) > z_alpha)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paired comparison [Not ready]<sup>[toc](#_toc)</sup>\n",
    "\n",
    "Если алгоритмы работали на одинаковых исходных данных, то $\\boldX$ и $\\boldY$ зависимы. В таком случае хотим протестировать, что выносятся одинаковые решения.\n",
    "$$\n",
    "D_i = I[X_i \\neq Y_i]\n",
    "$$\n",
    "\n",
    "Эквивалентность алгоритмов в данном случае следует понимать в том смысле, что они выносят одинаковые решения на одних и тех же данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas = np.array(results_mean) - np.array(results_median)\n",
    "delta_mean = np.mean(deltas)\n",
    "delta_std  = np.std(deltas)\n",
    "W = delta_mean / delta_std\n",
    "p_value = 2 * (1 - scipy.stats.norm.cdf(abs(W), loc=0.0, scale=1.0))\n",
    "print('W = {}, p_value = {}'.format(W, p_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='test_chi2_task1'></a>\n",
    "## Задача 3<sup>[toc](#_toc)</sup>\n",
    "Фирма предлагает 3 вида продукта. По данным прошлого года вероятности заказов для разных видов соответственно равны 0,1; 0, 65; 0,25. В этом году из 600 покупателей 42 приобрели продукт первого вида, 365 &mdash; второго, 193 &mdash; третьего. Можно ли считать, что предпочтения покупателей не изменились?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas = np.array([0.1, 0.65, 0.25])\n",
    "n_samples = 600\n",
    "values = np.array([42, 365, 193])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'estimated probas = {values / n_samples}')\n",
    "chi2_statistic = np.sum((values - n_samples * probas) ** 2 / (n_samples * probas))\n",
    "p_value = 1 - scipy.stats.chi2.cdf(chi2_statistic, df=len(values) - 1)\n",
    "print(f'chi2 statistic value = {chi2_statistic}')\n",
    "print(f'p-value = {p_value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='test_chi2_task2'></a>\n",
    "## Задача 4<sup>[toc](#_toc)</sup>\n",
    "В экспериментах с селекцией гороха Мендель наблюдал частоты различных видов семян, полученных при скрещивании растений с круглыми желтыми семенами и растений с морщинистыми зелеными семенами. Эти данные и значения теоретических вероятностей по теории наследственности приведены в следующей таблице:\n",
    "\n",
    "|Семена                | Частота | Вероятность |\n",
    "|---     |---  |---  |\n",
    "|Круглые и желтые      | 315 | 9/16 |\n",
    "|Морщинистые и желтые  | 101 | 3/16 |\n",
    "|Круглые и зеленые     | 108 | 3/16 |\n",
    "|Морщинистые и зеленые | 32  | 1/16 |\n",
    "\n",
    "Проверьте гипотезу $H_0$ о согласии частот с теоретическими вероятностями (на уровне значимости $\\alpha=0.1$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas = np.array([9, 3, 3, 1]) / 16.0\n",
    "counts = np.array([315, 101, 108, 32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = np.sum(counts)\n",
    "chi2_statistic = np.sum((counts - probas * n_samples)**2 / (probas * n_samples))\n",
    "p_value = 1 - scipy.stats.chi2.cdf(chi2_statistic, df=len(counts) - 1)\n",
    "print(f'chi2 statistic value = {chi2_statistic}')\n",
    "print(f'p-value = {p_value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='test_chi2_task3'></a>\n",
    "## Задача 5<sup>[toc](#_toc)</sup>\n",
    "\n",
    "Проверить гипотезу $H_0 \\colon \\Poisson(\\lambda)$, $\\lambda > 0$, но точное значение $\\lambda$ не дано.\n",
    "\n",
    "| $m$    | 0   | 1   | 2   | 3  | 4   | 5 |\n",
    "|---     |---  |---  |---  |--- | --- |---|\n",
    "| $n_i$  |  13 | 17  | 12  | 5  | 3   | 1 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Решение<sup>[toc](#_toc)</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Статистика хи-квадрат имеет вид\n",
    "$$\n",
    "T_{\\chi2}(\\boldX) = \\Sum_{i=0}^{M} \\frac{(n_i - np_{0i})^2}{np_{0i}}.\n",
    "$$\n",
    "Формально для распределения Пуассона $M = \\infty$, поэтому пойдем другим путем. \n",
    "\n",
    "Рассмотрим процесс тестирования гипотезы $H_0\\colon \\Poisson(\\lambda)$, т.е. при конкретном значении $\\lambda$. Определим вектор $\\boldp = (p_0, p_1, \\dots, p_K)$ следующим образом\n",
    "\\begin{align*}\n",
    "&p_0 = e^{-\\lambda},\\\\\n",
    "&p_1 = e^{-\\lambda} \\frac{\\lambda}{1!},\\\\\n",
    "&p_2 = e^{-\\lambda} \\frac{\\lambda^2}{2!},\\\\\n",
    "&\\dots \\\\\n",
    "&p_{K-1} = e^{-\\lambda} \\frac{\\lambda^{K-1}}{(K - 1)!},\\\\\n",
    "&p_K = e^{-\\lambda} \\frac{\\lambda^K}{K!} + e^{-\\lambda} \\frac{\\lambda^{K+1}}{(K + 1)!} + \\dots = \\Sum_{i = K}^{+\\infty} e^{-\\lambda}\\frac{\\lambda^i}{i!} = 1 - \\Sum_{i=0}^{K-1} p_i.\n",
    "\\end{align*}\n",
    "Теперь в решаемой задаче возьмем $K = 6$, и дополнительно положим, что $n_K = 0$ (вообще можно взять и $K < 6$, но тогда надо будет сгуппировать наблюдения $\\ge K$ в новый класс)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Максимум правдоподобия<sup>[toc](#_toc)</sup>\n",
    "\n",
    "Так как вероятность $p_K$ и выше в вычислении правдоподобия не участвуют, то результат максимум правдоподобия не меняется и вычисляется как и обычного распределения Пуассона:\n",
    "$$\n",
    "\\hat{\\lambda} = \\mean{\\boldX}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Статистика хи-квадрат<sup>[toc]</sup>\n",
    "$$\n",
    "T_{\\chi2}(\\boldX) = \\Sum_{i=0}^{K - 1} \\frac{(n_i - np_{0i}(\\hat{\\lambda}))^2}{np_{0i}(\\hat{\\lambda})} + n p_{0K}(\\lambda) \\xrightarrow[n \\to \\infty]{D} \\chi^2_{K - 1}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.array([13, 17, 12, 5, 3, 1, 0]) # N_0,...,N_{K-1}, N_K = 0\n",
    "assert counts[-1] == 0\n",
    "\n",
    "values = np.arange(len(counts))\n",
    "n_samples = np.sum(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling mu since scipy calls it mu\n",
    "mu = np.sum(values * counts) / n_samples\n",
    "probas = scipy.stats.poisson.pmf(values, mu=mu)\n",
    "probas[-1] = 1 - np.sum(probas[:-1])\n",
    "assert np.isclose(np.sum(probas), 1)\n",
    "\n",
    "print('Estimated (MLE) lambda =', mu)\n",
    "print('Estimated (MLE) probas =', probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_statistic = np.sum((counts - probas * n_samples)**2 / (probas * n_samples))\n",
    "p_value = 1 - scipy.stats.chi2.cdf(chi2_statistic, df=len(counts) - 2)\n",
    "print('chi statistic =', chi2_statistic)\n",
    "print('p-value =', p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='test_permutation_task1'></a>\n",
    "## Задача 6<sup>[toc](#_toc)</sup>\n",
    "Сгенерируем две выборки размера $n = 10$ каждая: $\\boldX_1$ из $\\Normal(\\mu_1, \\sigma^2)$ и $\\boldX_2$ из $\\Normal(\\mu_2, \\sigma^2)$, где $\\mu_1 = 0.7$, $\\mu=0.76$, $\\sigma=0.05$. Требуется с помощью теста перестановок найти p-value для гипотезы о том, что $H_0 \\colon \\mu_1 = \\mu_2$.\n",
    "\n",
    "TODO: Rewrite code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 3\n",
    "n_samples = 10\n",
    "mu1 = 0.70\n",
    "mu2 = 0.74\n",
    "sigma = 0.05\n",
    "X_len = Y_len = n_samples\n",
    "X_samples = scipy.stats.norm.rvs(size=X_len, loc=mu1, scale=sigma, random_state=random_state)\n",
    "Y_samples = scipy.stats.norm.rvs(size=Y_len, loc=mu2, scale=sigma, random_state=random_state + 1)\n",
    "for i, (x, y) in enumerate(zip(X_samples, Y_samples)):\n",
    "    print('i = {:<2}, x[i] = {:.3f}, y[i] = {:.3f}'.format(i, x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Тест перестановками<sup>[toc](#toc)</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "n_rejections = 0\n",
    "indices = np.array(list(range(X_len + Y_len)))\n",
    "\n",
    "obs_statistics = abs(np.mean(X_samples) - np.mean(Y_samples))\n",
    "XY_samples = np.concatenate([X_samples, Y_samples])\n",
    "XY_sum = np.sum(XY_samples)\n",
    "\n",
    "n_permutations = 0\n",
    "for X_indices in combinations(indices, X_len):\n",
    "    est_X_sum = np.sum(XY_samples[np.array(X_indices)])\n",
    "    mean_X_sum = est_X_sum / X_len\n",
    "    \n",
    "    est_Y_sum = XY_sum - est_X_sum\n",
    "    mean_Y_sum = est_Y_sum / Y_len \n",
    "    \n",
    "    n_rejections += int(abs(mean_X_sum - mean_Y_sum) > obs_statistics)\n",
    "    n_permutations += 1\n",
    "\n",
    "print('p_value =', n_rejections / n_permutations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Тест Вальда<sup>[toc](#_toc)</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean = np.mean(X_samples); X_mean_std = np.std(X_samples) / np.sqrt(X_len)\n",
    "Y_mean = np.mean(Y_samples); Y_mean_std = np.std(Y_samples) / np.sqrt(Y_len)\n",
    "W = abs(X_mean - Y_mean) / np.sqrt(X_mean_std ** 2 + Y_mean_std ** 2)\n",
    "pvalue = 2 * (1 - scipy.stats.norm.cdf(W))\n",
    "print('p_value =', pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='test_np_task1'></a>\n",
    "## Задача 7<sup>[toc](#_toc)</sup>\n",
    "Найдите наилучшую критическую область (НКО) для проверки гипотезы $H_0 \\colon \\Uniform[-a, a]$ против гипотезы $H_1 \\colon \\Normal(0, \\sigma)$ по одному\n",
    "наблюдению $(n = 1)$ при уровне значимости $\\alpha = 0.1$. Найдите мощность полученного критерия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='test_np_task2'></a>\n",
    "## Задача 8<sup>[toc](#toc)</sup>\n",
    "Проверяются гипотезы о плотности $f$ распределения наблюдений $\\boldX^n$: гипотеза $H_0\\colon f = f_0$ против альтернативы $H_1\\colon f = f_1$, где\n",
    "\\begin{gather*}\n",
    "f_1(x) = \n",
    "\\begin{cases}\n",
    "1, &x \\in [0,1],\\\\\n",
    "0, &x \\notin [0, 1],\n",
    "\\end{cases}\n",
    "\\qquad\n",
    "f_2(x)=\n",
    "\\begin{cases}\n",
    "2x, &x \\in [0, 1], \\\\\n",
    "0, &x \\notin [0, 1].\n",
    "\\end{cases}\n",
    "\\end{gather*}\n",
    "Построить наиболее мощный критерий размера $\\alpha$ при $n = 1$ и $n = 2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
